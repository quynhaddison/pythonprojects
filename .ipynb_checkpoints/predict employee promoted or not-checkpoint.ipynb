{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6f2ddffd",
   "metadata": {},
   "source": [
    "# Employee Promotion Prediction\n",
    "Addison 2024-03-15\n",
    "\n",
    "## I. Introduction\n",
    "\n",
    "The objective of this project is to build a model to identify which employees will be recommended for promotion based on a dataset containing 54,808 rows, each representing the demographics, backgrounds, and work performance of an employee. The dataset could be obtained through this link:\n",
    "\n",
    "https://www.kaggle.com/datasets/muhammadimran112233/employees-evaluation-for-promotion\n",
    "\n",
    "\n",
    "Here are the descriptions for all the columns:\n",
    "\n",
    "**employee_id** - Unique ID for the employee\n",
    "\n",
    "**department** - Department of employee\n",
    "\n",
    "**region** - Region of employment (unordered)\n",
    "\n",
    "**education** - Educational level of the employee\n",
    "\n",
    "**gender** - The employee's gender (**m:** Male, **f:** Female)\n",
    "\n",
    "**recruitment_channel** - The channel from which the employee was recruited\n",
    "\n",
    "**no_of_trainings** - The number of trainings that the employee completed last year\n",
    " \n",
    "**age** - The employee's age\n",
    "\n",
    "**previous_year_rating** - The employee's rating score from the previous year (**min:** 1, **max:** 5)\n",
    "\n",
    "**length_of_service** - The number of years that the employee has worked for the company\n",
    "\n",
    "**awards_won** - If the employee won any awards during the previous year, it is denoted as 1; otherwise, it is 0\n",
    "\n",
    "**avg_training_score** - The employee's average score in current training evaluations (**min:** 0, **max:** 100)\n",
    "\n",
    "**is_promoted** - If the employee is recommended for promotion, it is denoted as 1; otherwise, it is 0   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "de56af9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, mean_squared_error, mean_absolute_error\n",
    "from sklearn.metrics import r2_score, precision_score, f1_score\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b87771f",
   "metadata": {},
   "source": [
    "## II. Data exploration\n",
    "\n",
    "To begin, let's take a brief glance at the initial rows of the data and gather key details to visualize the data's appearance. This includes exploring the data types of columns, as well as noting the count of unique values and non-null entries in each column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0552f16f",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'employee_promotion.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [2]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43memployee_promotion.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m data\u001b[38;5;241m.\u001b[39mhead()\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/util/_decorators.py:311\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    305\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[1;32m    306\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    307\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39marguments),\n\u001b[1;32m    308\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[1;32m    309\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mstacklevel,\n\u001b[1;32m    310\u001b[0m     )\n\u001b[0;32m--> 311\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/io/parsers/readers.py:680\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    665\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    666\u001b[0m     dialect,\n\u001b[1;32m    667\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    676\u001b[0m     defaults\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdelimiter\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[1;32m    677\u001b[0m )\n\u001b[1;32m    678\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 680\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/io/parsers/readers.py:575\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    572\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    574\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 575\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    577\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    578\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/io/parsers/readers.py:933\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    930\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    932\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 933\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1217\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1213\u001b[0m     mode \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1214\u001b[0m \u001b[38;5;66;03m# error: No overload variant of \"get_handle\" matches argument types\u001b[39;00m\n\u001b[1;32m   1215\u001b[0m \u001b[38;5;66;03m# \"Union[str, PathLike[str], ReadCsvBuffer[bytes], ReadCsvBuffer[str]]\"\u001b[39;00m\n\u001b[1;32m   1216\u001b[0m \u001b[38;5;66;03m# , \"str\", \"bool\", \"Any\", \"Any\", \"Any\", \"Any\", \"Any\"\u001b[39;00m\n\u001b[0;32m-> 1217\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[call-overload]\u001b[39;49;00m\n\u001b[1;32m   1218\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1219\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1220\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1221\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1222\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1223\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1224\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1225\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1226\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1227\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1228\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/io/common.py:789\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    784\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    785\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    786\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    787\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    788\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 789\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    790\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    791\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    792\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    793\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    794\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    795\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    796\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    797\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    798\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'employee_promotion.csv'"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('employee_promotion.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a4a95ec",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11f2c710",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "121af058",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f18d8ab1",
   "metadata": {},
   "source": [
    "From the statistics above, it's noticeable that columns **'education', 'previous_year_rating', and 'avg_training_score'** have null values. Since the total number of null values is quite significant compared to the whole dataset, we'll fill in such null values later."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05fa5074",
   "metadata": {},
   "source": [
    "Now, we will visualize the categorical variables for exploratory purposes. Specifically, we'll examine the proportion of employees who are recommended to be promoted versus those who are not in each **department, educational level, gender group, recruitment channel, previous year's rating group, and award winning group.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ea59c8c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Set the style to white\n",
    "sns.set_style(\"white\")\n",
    "\n",
    "# Set the palette to Set2\n",
    "sns.set_palette(\"Set2\")\n",
    "\n",
    "cat_columns = ['department', 'education', 'gender', 'recruitment_channel', 'previous_year_rating', 'awards_won']\n",
    "fig, axes = plt.subplots(3, 2, figsize=(16, 15))\n",
    "\n",
    "# Create a single legend for all subplots\n",
    "handles, labels = None, None\n",
    "\n",
    "for i, (col, ax) in enumerate(zip(cat_columns, axes.flatten())):\n",
    "    counts = data.groupby([col, 'is_promoted']).size().unstack()\n",
    "    counts.plot.bar(stacked=True, ax=ax)\n",
    "    ax.set_xlabel(col.capitalize())\n",
    "    \n",
    "    # Rotate x-labels by 60 degrees if col is 'department'\n",
    "    rotation_angle = 45 if col == 'department' else 0\n",
    "    ax.set_xticklabels(ax.get_xticklabels(), rotation=rotation_angle, ha='center')\n",
    "\n",
    "    # Store handles and labels for creating a single legend\n",
    "    if i == 0:\n",
    "        handles, labels = ax.get_legend_handles_labels()\n",
    "        ax.legend(handles=handles, labels=['Not Promoted', 'Promoted'], loc='upper left', bbox_to_anchor=(0.02, 0.98))  # Adjust the bbox_to_anchor as needed\n",
    "    else:\n",
    "        ax.get_legend().remove()\n",
    "\n",
    "# Add a single legend\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ab3ccef",
   "metadata": {},
   "source": [
    "From the charts above, it's evident that the proportion of employees who are recommended to be promoted versus those who are not in each category is significantly imbalanced. Thus, we'll use the **weighted and micro** averaging methods to compute precision and F1 scores of our prediction model later.\n",
    "\n",
    "The number of employees who are recommended to be promoted also has a **positive correlation** with the total number of employees in each category: the higher the number of employees in a certain category, the higher the number of employees who are recommended to be promoted in that category.\n",
    "\n",
    "The **Sales & Marketing department** has the highest number of employees (roughly 17k) and those who are recommended to be promoted (roughly 1.2k), followed by the Operations department (roughly 11k employees and 1k employees recommended to be promoted).\n",
    "\n",
    "The majority of employees hold a **Bachelor's degree** (approximately 28k), among whom there are about 3k employees who are recommended to be promoted, followed by those holding a Master's degree (roughly 15k employees and 1.5k employees recommended to be promoted).\n",
    "\n",
    "**Male employees** also significantly outnumber their counterparts (roughly 38k vs roughly 16k). The number of male employees who are recommended to be promoted is roughly double that of their counterparts.\n",
    "\n",
    "Most employees are recruited from **channels other than sourcing and referral** (approximately 30k vs 23k vs 1k). Roughly 2.5k employees who are recruited from other channels are recommended to be promoted, while roughly 2k employees who are recruited via sourcing are recommended to be promoted.\n",
    "\n",
    "Employees with **higher previous year's rating scores** tend to be recommended for promotion. The majority of employees receive a previous year's rating score of 3.0 (roughly 18k). However, the majority of employees who are recommended for promotion are those receiving a previous year's rating score of 5.0 (roughly 2k), followed by those who receive a previous year's rating score of 3.0 (roughly 1.5k).\n",
    "\n",
    "Although the majority of employees recommended for promotion did not win any awards the previous year (roughly 4k), **employees winning awards last year** have a more significant probability of being recommended for promotion (0.44 vs 0.07).\n",
    "\n",
    "Now, we are going to examine the proportion of employees who are recommended to be promoted versus those who are not in each **region of employment.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c5e4c1d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Set the style to white\n",
    "sns.set_style(\"white\")\n",
    "\n",
    "# Set the palette to Set2\n",
    "sns.set_palette(\"Set2\")\n",
    "\n",
    "# Group data by region and promotion status, then count the occurrences\n",
    "promotion_counts = data.groupby(['region', 'is_promoted']).size().unstack()\n",
    "\n",
    "# Enlarge the plot by adjusting the figsize parameter in plt.subplots()\n",
    "fig, ax = plt.subplots(figsize=(16, 10))\n",
    "\n",
    "# Plot the promotion counts for each region\n",
    "promotion_counts.plot(kind='bar', stacked=True, ax=ax)\n",
    "plt.title('Promotion Status in Each Region')\n",
    "plt.xticks(rotation= 45, ha='right')\n",
    "plt.legend(['Not Promoted', 'Promoted'], loc='upper right')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc196347",
   "metadata": {},
   "source": [
    "From the chart above, it's noticeable that the majority of employees, as well as those who are recommended to be promoted, are from **region 2** (roughly 12.5k), followed by region 22 and region 7.\n",
    "\n",
    "Now, we're going to examine the distribution of employees who are recommended to be promoted and those who are not across different discrete variables: **'no_of_trainings', 'age', 'length_of_service', and 'avg_training_score'.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2de22c37",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "column = ['no_of_trainings', 'avg_training_score', 'age','length_of_service']\n",
    "fig = plt.figure(figsize=(16,10))\n",
    "\n",
    "for i, col in enumerate(column):\n",
    "    ax = plt.subplot(2, 2, i+1)\n",
    "    sns.violinplot(y=data[col], x=data[\"is_promoted\"], ax=ax, hue = data[\"is_promoted\"], palette='Set2', legend=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88cc76f9",
   "metadata": {},
   "source": [
    "Based on the charts above, it's clear that the tendency of being recommended for promotion is likely dependent on the **average score in current training evaluations** rather than the **number of trainings** that the employee completed last year. The higher the average score in current training evaluations, the higher the chance of being recommended for promotion.\n",
    "\n",
    "Regarding **'age' and 'length_of_service'**, the distribution of employees recommended for promotion and those who are not is quite similar. Thus, it could be implied that **'age' and 'length_of_service'** are not crucial factors determining the tendency of being recommended for promotion. The majority of employees recommended for promotion are around 30 years old and have worked for the company for roughly 2-3 years.\n",
    "\n",
    "## III. Data imputation\n",
    "\n",
    "Now, we're going to fill in null rows in columns  **'education', 'previous_year_rating', and 'avg_training_score'**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d938168c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Count the frequency of each unique value in the 'education' column\n",
    "data['education'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c171bc84",
   "metadata": {},
   "source": [
    "Since the **\"education\"** classes are categorical and imbalanced in the dataset, the model's performance may be biased towards the majority class. In such cases, using the **mode method** may result in better predictions for the missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "456d9fd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill missing values in the 'education' column with the mode (most frequent value)\n",
    "data['education'].fillna(value=data['education'].mode()[0], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b5a4c60",
   "metadata": {},
   "source": [
    "Next, we're going to plot the distribution of **'previous_year_rating'**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b12750b4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sns.set_palette(\"flare\")\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "data['previous_year_rating'].hist(bins=5, edgecolor='black', alpha=0.7)\n",
    "plt.title('Histogram of Previous Year Ratings')\n",
    "plt.xlabel('Rating')\n",
    "plt.ylabel('Frequency')\n",
    "plt.grid(axis='y', alpha=0.7)\n",
    "plt.tight_layout()\n",
    "plt.grid(False) \n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bd1b66b",
   "metadata": {},
   "source": [
    "Based on the chart above, it's evident that **'previous_year_rating'** is normally distributed. Since it's also categorical, we'll use the **mode method** to fill in missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab6719d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill missing values in the 'previous_year_rating' column with the mode value\n",
    "data['previous_year_rating'].fillna(value=data['previous_year_rating'].mode()[0], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1af9c370",
   "metadata": {},
   "source": [
    "Next, we're going to plot the distribution of **'avg_training_score'**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ade6b51b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Plot histogram of 'avg_training_score' column\n",
    "sns.set_palette(\"Set2\")\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "data['avg_training_score'].hist(bins=20, edgecolor='black', alpha=0.7)\n",
    "plt.title('Histogram of Average Training Scores')\n",
    "plt.xlabel('Average Training Score')\n",
    "plt.ylabel('Frequency')\n",
    "plt.grid(False) \n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c10ef971",
   "metadata": {},
   "source": [
    "Based on the chart above, it's evident that **'avg_training_score'** is right-skewed distributed. Since it's also discrete, we'll use the **median method** to fill in missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef21bce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill missing values in the 'avg_training_score' column with the median value\n",
    "data['avg_training_score'].fillna(value=data['avg_training_score'].median(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "260d0d0d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Check for missing values in the DataFrame\n",
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "affaa6b3",
   "metadata": {},
   "source": [
    "The statistics above indicate that our dataset is now free of null values and ready for building a predictive model.\n",
    "\n",
    "## IV. Data engineering\n",
    "\n",
    "To avoid the SettingWithCopyWarning error, we'll slice our dataset as shown below without making any alterations to the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cd8c652",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.loc[:, 'employee_id': 'is_promoted']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42420e8b",
   "metadata": {},
   "source": [
    "Next, we'll convert **'department', 'region', 'education', 'gender', 'recruitment_channel', 'previous_year_rating'** columns to categorical codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30ec2557",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"department\"] = data[\"department\"].astype(\"category\").cat.codes\n",
    "data[\"region\"] = data[\"region\"].astype(\"category\").cat.codes\n",
    "data[\"education\"] = data[\"education\"].astype(\"category\").cat.codes\n",
    "data[\"gender\"] = data[\"gender\"].astype(\"category\").cat.codes\n",
    "data[\"recruitment_channel\"] = data[\"recruitment_channel\"].astype(\"category\").cat.codes\n",
    "data[\"previous_year_rating\"] = data[\"previous_year_rating\"].astype(\"category\").cat.codes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e5043de",
   "metadata": {},
   "source": [
    "## V. Predictive model building and evaluation\n",
    "\n",
    "\n",
    "Next, we'll drop **'is_promoted' and 'employee_id'** from the dataset and assign the new dataset to variable **X**. In this project, we'll use all variables except **'employee_id'** to predict whether employees will be recommended to be promoted.\n",
    "\n",
    "Then, we'll assign the target variable **'is_promoted'** to variable **y**.\n",
    "\n",
    "Afterwards, we'll split the dataset into training and testing sets and allocate 20% of the data for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b380940",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop([\"is_promoted\",'employee_id' ], axis=1)\n",
    "y = data[\"is_promoted\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state = 777)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fd8f91f",
   "metadata": {},
   "source": [
    "In this project, we'll use **Random Forest classifier** for our predictive model and **weighted** and **mircro** averaging methods when calculating precision and f1 score.\n",
    "\n",
    "**Micro averaging** helps highlight the overall effectiveness of the model, while **weighted averaging** provides insights into its performance on individual classes, especially those that are less underrepresented. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3468710",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Initialize the Random Forest classifier with specified hyperparameters\n",
    "rf = RandomForestClassifier(max_depth=10, min_samples_split=15, n_estimators=25, random_state=222)\n",
    "\n",
    "# Train the Random Forest classifier on the training data\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "preds = rf.predict(X_test)\n",
    "\n",
    "# Calculate the accuracy of the predictions\n",
    "accuracy = accuracy_score(y_test, preds)\n",
    "\n",
    "# Calculate the precision of the predictions\n",
    "precision = precision_score(y_test, preds, average='weighted')\n",
    "\n",
    "# Calculate the F1 score of the predictions\n",
    "f1 = f1_score(y_test, preds, average='weighted')\n",
    "\n",
    "# Print the precision, accuracy, and F1 score\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision - weighted: {precision:.4f}\")\n",
    "print(f\"F1 score - weighted: {f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "badd5568",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the precision of the predictions\n",
    "precision = precision_score(y_test, preds, average='micro')\n",
    "\n",
    "# Calculate the F1 score of the predictions\n",
    "f1 = f1_score(y_test, preds, average='micro')\n",
    "\n",
    "# Print the precision, accuracy, and F1 score\n",
    "print(f\"Precision - micro: {precision:.4f}\")\n",
    "print(f\"F1 score - mirco: {f1:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "516389e9",
   "metadata": {},
   "source": [
    "From the scores above, it's evident that our predictive model produces reliable results since all the scores are above 90%.\n",
    "\n",
    "Next, we're going to **evaluate the importance of our predictors.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ece74ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importances = rf.feature_importances_\n",
    "\n",
    "feature_names = X_train.columns\n",
    "\n",
    "# Dictionary to associate features with their importance scores\n",
    "feature_importance_dict = dict(zip(feature_names, feature_importances))\n",
    "\n",
    "# Sort the features by importance in descending order\n",
    "sorted_features = sorted(feature_importance_dict.items(), key = lambda x: x[1], reverse = True)\n",
    "\n",
    "# Print the sorted feature importances\n",
    "for feature, importance in sorted_features:\n",
    "    print(f\"{feature}: {importance}\")\n",
    "\n",
    "# Plotting\n",
    "sns.set_palette(\"flare\")\n",
    "\n",
    "plt.figure(figsize = (10, 6))\n",
    "plt.bar(range(len(sorted_features)), [importance for feature, importance in sorted_features], align = \"center\")\n",
    "plt.xticks(range(len(sorted_features)), [feature for feature, importance in sorted_features], rotation=45, ha=\"right\")\n",
    "plt.xlabel(\"Feature\")\n",
    "plt.ylabel(\"Importance\")\n",
    "plt.title(\"Feature Importance in Random Forest\")\n",
    "plt.grid(False) \n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48354516",
   "metadata": {},
   "source": [
    "From the chart above, it's noticeable that **avg_training_score** is the most important feature (48%) to predict whether employees will be recommended to be promoted, followed by **awards_won** (14%), **previous_year_rating** (12%), and **department** (11%). The other factors contribute below 4% to the predictive model.\n",
    "\n",
    "## VI. Conclusions and suggestions for future research\n",
    "\n",
    "The accuracy and precision rates of the prediction model are impressive, suggesting that the model produces reliable results. However, further research could explore alternative methods for handling missing data and consider employing neural network techniques to enhance the predictive model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
